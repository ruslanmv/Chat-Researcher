{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7236085f-d29b-4661-9bbb-38cb092290f1",
   "metadata": {},
   "source": [
    "# Arxiv Chatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bd2a28-6967-4dd7-a74c-2c0b7cf232d2",
   "metadata": {},
   "source": [
    "First we we will create a program that will find the relevant papers about a subject.\n",
    "\n",
    "In this case let us talk about  `Large Language Models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "200cbe69-396d-4665-9760-b8f8fb1e2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import fitz\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import gradio as gr\n",
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# Compability with Hugging Face models\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "import torch\n",
    "import gradio as gr\n",
    "import re\n",
    "# Compability with ChatGPT\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12639e0c-b905-40a5-a397-efb974679422",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='Large Language Models LLM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088671b9-2931-4d83-8a87-bc04e8bef05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Several categories of Large Language Models (LLMs): A Short Survey\n",
      "On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models\n",
      "llm-japanese-dataset v0: Construction of Japanese Chat Dataset for Large Language Models and its Methodology\n",
      "TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series\n",
      "FATE-LLM: A Industrial Grade Federated Learning Framework for Large Language Models\n",
      "Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training\n",
      "Instruct-Align: Teaching Novel Languages with to LLMs through Alignment-based Cross-Lingual Instruction\n",
      "Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM\n",
      "Large Language Models are Effective Table-to-Text Generators, Evaluators, and Feedback Providers\n",
      "mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "search = arxiv.Search(\n",
    "  query = topic,\n",
    "  max_results = 10,\n",
    "  sort_by = arxiv.SortCriterion.Relevance\n",
    ")\n",
    "for result in arxiv.Client().results(search):\n",
    "  print(result.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2b165e-65e9-4905-b330-3f330b4cad81",
   "metadata": {},
   "source": [
    "## Building our Dataframe of our Topic in Arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846dfb83-f455-4124-8ce1-619605f70bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [result.title for result in arxiv.Client().results(search)]\n",
    "authors = [result.authors for result in arxiv.Client().results(search)]\n",
    "summary = [result.summary for result in arxiv.Client().results(search)]\n",
    "entry_id = [result.entry_id for result in arxiv.Client().results(search)]\n",
    "#download_source = [result.download_source for result in arxiv.Client().results(search)]\n",
    "#download_pdf = [result.download_pdf for result in arxiv.Client().results(search)]\n",
    "pdf_url = [result.pdf_url for result in arxiv.Client().results(search)]\n",
    "categories = [result.categories for result in arxiv.Client().results(search)]\n",
    "comment = [result.comment for result in arxiv.Client().results(search)]\n",
    "doi = [result.doi for result in arxiv.Client().results(search)]\n",
    "published = [result.published for result in arxiv.Client().results(search)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd93c0b0-7422-4cfb-a705-351795b040fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85bab6d-8d79-476b-8e83-2adafd913465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'title': titles,\n",
    "    'authors': authors,\n",
    "    'summary': summary,\n",
    "    #'entry_id': entry_id,\n",
    "    'pdf_url':pdf_url,\n",
    "    'categories':categories,\n",
    "    'published':published\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84415799-bd27-4402-8c88-7e410fb383d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, 'id', range(1, len(df) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f2ff5e9-510f-431a-a9e1-c3d2d089fd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 results were found.\n"
     ]
    }
   ],
   "source": [
    "print(f'{df.shape[0]} results were found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73ebab8e-4679-4560-9c7a-737691dfb903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>summary</th>\n",
       "      <th>pdf_url</th>\n",
       "      <th>categories</th>\n",
       "      <th>published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Several categories of Large Language Models (L...</td>\n",
       "      <td>[Saurabh Pahune, Manoj Chandrasekharan]</td>\n",
       "      <td>Large Language Models(LLMs)have become effecti...</td>\n",
       "      <td>http://arxiv.org/pdf/2307.10188v1</td>\n",
       "      <td>[cs.CL, cs.LG]</td>\n",
       "      <td>2023-07-05 18:18:23+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>On the Origin of LLMs: An Evolutionary Tree an...</td>\n",
       "      <td>[Sarah Gao, Andrew Kean Gao]</td>\n",
       "      <td>Since late 2022, Large Language Models (LLMs) ...</td>\n",
       "      <td>http://arxiv.org/pdf/2307.09793v1</td>\n",
       "      <td>[cs.DL, cs.CL, I.2.1; H.5.0]</td>\n",
       "      <td>2023-07-19 07:17:43+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>llm-japanese-dataset v0: Construction of Japan...</td>\n",
       "      <td>[Masanori Hirano, Masahiro Suzuki, Hiroki Sakaji]</td>\n",
       "      <td>This study constructed a Japanese chat dataset...</td>\n",
       "      <td>http://arxiv.org/pdf/2305.12720v1</td>\n",
       "      <td>[cs.CL, cs.AI]</td>\n",
       "      <td>2023-05-22 04:59:33+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>TEST: Text Prototype Aligned Embedding to Acti...</td>\n",
       "      <td>[Chenxi Sun, Yaliang Li, Hongyan Li, Shenda Hong]</td>\n",
       "      <td>This work summarizes two strategies for comple...</td>\n",
       "      <td>http://arxiv.org/pdf/2308.08241v1</td>\n",
       "      <td>[cs.CL, cs.AI]</td>\n",
       "      <td>2023-08-16 09:16:02+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>FATE-LLM: A Industrial Grade Federated Learnin...</td>\n",
       "      <td>[Tao Fan, Yan Kang, Guoqiang Ma, Weijing Chen,...</td>\n",
       "      <td>Large Language Models (LLMs), such as ChatGPT,...</td>\n",
       "      <td>http://arxiv.org/pdf/2310.10049v1</td>\n",
       "      <td>[cs.LG, cs.AI]</td>\n",
       "      <td>2023-10-16 04:17:13+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Alphazero-like Tree-Search can Guide Large Lan...</td>\n",
       "      <td>[Xidong Feng, Ziyu Wan, Muning Wen, Ying Wen, ...</td>\n",
       "      <td>Large language models (LLMs) typically employ ...</td>\n",
       "      <td>http://arxiv.org/pdf/2309.17179v1</td>\n",
       "      <td>[cs.LG, cs.AI, cs.CL]</td>\n",
       "      <td>2023-09-29 12:20:19+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Instruct-Align: Teaching Novel Languages with ...</td>\n",
       "      <td>[Samuel Cahyawijaya, Holy Lovenia, Tiezheng Yu...</td>\n",
       "      <td>Instruction-tuned large language models (LLMs)...</td>\n",
       "      <td>http://arxiv.org/pdf/2305.13627v1</td>\n",
       "      <td>[cs.CL, cs.AI]</td>\n",
       "      <td>2023-05-23 02:51:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Defending Against Alignment-Breaking Attacks v...</td>\n",
       "      <td>[Bochuan Cao, Yuanpu Cao, Lu Lin, Jinghui Chen]</td>\n",
       "      <td>Recently, Large Language Models (LLMs) have ma...</td>\n",
       "      <td>http://arxiv.org/pdf/2309.14348v1</td>\n",
       "      <td>[cs.CL, cs.AI, cs.CR, cs.LG]</td>\n",
       "      <td>2023-09-18 02:07:22+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Large Language Models are Effective Table-to-T...</td>\n",
       "      <td>[Yilun Zhao, Haowei Zhang, Shengyun Si, Linyon...</td>\n",
       "      <td>Large language models (LLMs) have shown remark...</td>\n",
       "      <td>http://arxiv.org/pdf/2305.14987v1</td>\n",
       "      <td>[cs.CL]</td>\n",
       "      <td>2023-05-24 10:22:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>mBLIP: Efficient Bootstrapping of Multilingual...</td>\n",
       "      <td>[Gregor Geigle, Abhay Jain, Radu Timofte, Gora...</td>\n",
       "      <td>Modular vision-language models (Vision-LLMs) a...</td>\n",
       "      <td>http://arxiv.org/pdf/2307.06930v2</td>\n",
       "      <td>[cs.CV, cs.CL]</td>\n",
       "      <td>2023-07-13 17:51:58+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  Several categories of Large Language Models (L...   \n",
       "1   2  On the Origin of LLMs: An Evolutionary Tree an...   \n",
       "2   3  llm-japanese-dataset v0: Construction of Japan...   \n",
       "3   4  TEST: Text Prototype Aligned Embedding to Acti...   \n",
       "4   5  FATE-LLM: A Industrial Grade Federated Learnin...   \n",
       "5   6  Alphazero-like Tree-Search can Guide Large Lan...   \n",
       "6   7  Instruct-Align: Teaching Novel Languages with ...   \n",
       "7   8  Defending Against Alignment-Breaking Attacks v...   \n",
       "8   9  Large Language Models are Effective Table-to-T...   \n",
       "9  10  mBLIP: Efficient Bootstrapping of Multilingual...   \n",
       "\n",
       "                                             authors  \\\n",
       "0            [Saurabh Pahune, Manoj Chandrasekharan]   \n",
       "1                       [Sarah Gao, Andrew Kean Gao]   \n",
       "2  [Masanori Hirano, Masahiro Suzuki, Hiroki Sakaji]   \n",
       "3  [Chenxi Sun, Yaliang Li, Hongyan Li, Shenda Hong]   \n",
       "4  [Tao Fan, Yan Kang, Guoqiang Ma, Weijing Chen,...   \n",
       "5  [Xidong Feng, Ziyu Wan, Muning Wen, Ying Wen, ...   \n",
       "6  [Samuel Cahyawijaya, Holy Lovenia, Tiezheng Yu...   \n",
       "7    [Bochuan Cao, Yuanpu Cao, Lu Lin, Jinghui Chen]   \n",
       "8  [Yilun Zhao, Haowei Zhang, Shengyun Si, Linyon...   \n",
       "9  [Gregor Geigle, Abhay Jain, Radu Timofte, Gora...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Large Language Models(LLMs)have become effecti...   \n",
       "1  Since late 2022, Large Language Models (LLMs) ...   \n",
       "2  This study constructed a Japanese chat dataset...   \n",
       "3  This work summarizes two strategies for comple...   \n",
       "4  Large Language Models (LLMs), such as ChatGPT,...   \n",
       "5  Large language models (LLMs) typically employ ...   \n",
       "6  Instruction-tuned large language models (LLMs)...   \n",
       "7  Recently, Large Language Models (LLMs) have ma...   \n",
       "8  Large language models (LLMs) have shown remark...   \n",
       "9  Modular vision-language models (Vision-LLMs) a...   \n",
       "\n",
       "                             pdf_url                    categories  \\\n",
       "0  http://arxiv.org/pdf/2307.10188v1                [cs.CL, cs.LG]   \n",
       "1  http://arxiv.org/pdf/2307.09793v1  [cs.DL, cs.CL, I.2.1; H.5.0]   \n",
       "2  http://arxiv.org/pdf/2305.12720v1                [cs.CL, cs.AI]   \n",
       "3  http://arxiv.org/pdf/2308.08241v1                [cs.CL, cs.AI]   \n",
       "4  http://arxiv.org/pdf/2310.10049v1                [cs.LG, cs.AI]   \n",
       "5  http://arxiv.org/pdf/2309.17179v1         [cs.LG, cs.AI, cs.CL]   \n",
       "6  http://arxiv.org/pdf/2305.13627v1                [cs.CL, cs.AI]   \n",
       "7  http://arxiv.org/pdf/2309.14348v1  [cs.CL, cs.AI, cs.CR, cs.LG]   \n",
       "8  http://arxiv.org/pdf/2305.14987v1                       [cs.CL]   \n",
       "9  http://arxiv.org/pdf/2307.06930v2                [cs.CV, cs.CL]   \n",
       "\n",
       "                  published  \n",
       "0 2023-07-05 18:18:23+00:00  \n",
       "1 2023-07-19 07:17:43+00:00  \n",
       "2 2023-05-22 04:59:33+00:00  \n",
       "3 2023-08-16 09:16:02+00:00  \n",
       "4 2023-10-16 04:17:13+00:00  \n",
       "5 2023-09-29 12:20:19+00:00  \n",
       "6 2023-05-23 02:51:34+00:00  \n",
       "7 2023-09-18 02:07:22+00:00  \n",
       "8 2023-05-24 10:22:30+00:00  \n",
       "9 2023-07-13 17:51:58+00:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ae7f0be-9745-4eba-954d-aa92273baba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    http://arxiv.org/pdf/2307.10188v1\n",
       "1    http://arxiv.org/pdf/2307.09793v1\n",
       "2    http://arxiv.org/pdf/2305.12720v1\n",
       "3    http://arxiv.org/pdf/2308.08241v1\n",
       "4    http://arxiv.org/pdf/2310.10049v1\n",
       "5    http://arxiv.org/pdf/2309.17179v1\n",
       "6    http://arxiv.org/pdf/2305.13627v1\n",
       "7    http://arxiv.org/pdf/2309.14348v1\n",
       "8    http://arxiv.org/pdf/2305.14987v1\n",
       "9    http://arxiv.org/pdf/2307.06930v2\n",
       "Name: pdf_url, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pdf_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851b0c3b-f725-4e4d-9af6-e47272cdf229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd412ab7-ee37-4b38-9015-f7f76fe806f8",
   "metadata": {},
   "source": [
    "# Step 1 - PDF Analizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315940d8-b33d-4f38-8cad-486dcbbe122d",
   "metadata": {},
   "source": [
    "\n",
    "The first example that we will use in this notebookwill we  will take the  the most relevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6925f094-1c0d-4c71-98eb-5ca3f327aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = df['pdf_url'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a15b8c9f-8235-4af5-bb28-ab947e9e5b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://arxiv.org/pdf/2307.10188v1\n"
     ]
    }
   ],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c22e3b98-f09f-4226-8043-0c5fe3b1b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(url, output_path):\n",
    "    urllib.request.urlretrieve(url, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4ce3543-15ff-4828-a065-77aef60f8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_file = \"document.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f205db-2491-4050-8909-e499c88ade83",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_pdf(url, downloaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a47ca8e-6f33-49a0-8f30-c47cb8125f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(path, start_page=1, end_page=None):\n",
    "    doc = fitz.open(path)\n",
    "    total_pages = doc.page_count\n",
    "\n",
    "    if end_page is None:\n",
    "        end_page = total_pages\n",
    "\n",
    "    text_list = []\n",
    "\n",
    "    for i in range(start_page-1, end_page):\n",
    "        text = doc.load_page(i).get_text(\"text\")\n",
    "        text = preprocess(text)\n",
    "        text_list.append(text)\n",
    "\n",
    "    doc.close()\n",
    "    return text_list\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7af4df2b-9264-4c1e-b33c-76f89cffea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = pdf_to_text(downloaded_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f26a0e9d-f5fa-420b-b9e6-2db6dc7e23ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c031958a-dfeb-4c35-8634-3ef17d07031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_chunks(texts, word_length=150, start_page=1):\n",
    "    text_toks = [t.split(' ') for t in texts]\n",
    "    page_nums = []\n",
    "    chunks = []\n",
    "    \n",
    "    for idx, words in enumerate(text_toks):\n",
    "        for i in range(0, len(words), word_length):\n",
    "            chunk = words[i:i+word_length]\n",
    "            if (i+word_length) > len(words) and (len(chunk) < word_length) and (\n",
    "                len(text_toks) != (idx+1)):\n",
    "                text_toks[idx+1] = chunk + text_toks[idx+1]\n",
    "                continue\n",
    "            chunk = ' '.join(chunk).strip()\n",
    "            chunk = f'[Page no. {idx+start_page}]' + ' ' + '\"' + chunk + '\"'\n",
    "            chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae794335-c597-4d28-bee3-9b059d9a37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks= text_to_chunks(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b33a38c-6f8b-46eb-a91f-4fd9453e5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bda21220-ce95-48eb-a43f-a251bf48d83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Page no. 1] \"Several categories of Large Language Models (LLMs): A Short Survey Saurabh Pahune 1,†,‡, Manoj Chandrasekharan 2 1 Cardinal Health, Dublin OH 43017, USA; Email: saurabh.pahune@cardinalhealth.com, Tel.:+1-901-691-7551 2 Email: manoj.c@memphis.edu Abstract: Large Language Models (LLMs) have become effective tools for natural language process- ing and have been used in many different ﬁelds. This essay offers a succinct summary of various LLM subcategories. The survey emphasizes recent developments and efforts made for various LLM kinds, including task-based ﬁnancial LLMs, multilingual language LLMs, biomedical and clinical LLMs, vision language LLMs, and code language models. The survey gives a general summary of the methods, attributes, datasets, transformer models, and comparison metrics applied in each category of LLMs. Furthermore, it highlights unresolved problems in the ﬁeld of developing chatbots and virtual assistants, such as boosting natural language processing, enhancing chatbot intelligence, and resolving moral and legal dilemmas. The purpose of this study is to provide\"']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e30f544d-cbd0-40dd-ad77-263afbbd8006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 68 pieces of the article now\n"
     ]
    }
   ],
   "source": [
    "print(\"We have {} pieces of the article now\".format(parts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97527b6a-4657-44c2-a3c4-20287c8da5ec",
   "metadata": {},
   "source": [
    "Now above all the list of 41 pieces, we should reduce the amount of pieces, this is possible by usuing the Semantic Search.\n",
    "Thie is great model used by Google that his the universal sentence encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b857e8e-0777-4ffd-8621-8e606a112da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSearch:\n",
    "    def __init__(self):\n",
    "        self.use = hub.load('https://tfhub.dev/google/universal-sentence-encoder/4')\n",
    "        self.fitted = False\n",
    "    def fit(self, data, batch=1000, n_neighbors=5):\n",
    "        self.data = data\n",
    "        self.embeddings = self.get_text_embedding(data, batch=batch)\n",
    "        n_neighbors = min(n_neighbors, len(self.embeddings))\n",
    "        self.nn = NearestNeighbors(n_neighbors=n_neighbors)\n",
    "        self.nn.fit(self.embeddings)\n",
    "        self.fitted = True\n",
    "    def __call__(self, text, return_data=True):\n",
    "        inp_emb = self.use([text])\n",
    "        neighbors = self.nn.kneighbors(inp_emb, return_distance=False)[0]\n",
    "        if return_data:\n",
    "            return [self.data[i] for i in neighbors]\n",
    "        else:\n",
    "            return neighbors\n",
    "    def get_text_embedding(self, texts, batch=1000):\n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch):\n",
    "            text_batch = texts[i:(i+batch)]\n",
    "            emb_batch = self.use(text_batch)\n",
    "            embeddings.append(emb_batch)\n",
    "        embeddings = np.vstack(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570371af-15be-45a4-a934-8c89ba805487",
   "metadata": {},
   "source": [
    "We summarize all the previous steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f90f2e3-cba1-4bc2-b6f2-f981e7903080",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender = SemanticSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29ea63c1-0058-416e-bba9-32d3a4a0f99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recommender(path, start_page=1):\n",
    "    global recommender\n",
    "    texts = pdf_to_text(path, start_page=start_page)\n",
    "    chunks = text_to_chunks(texts, start_page=start_page)\n",
    "    recommender.fit(chunks)\n",
    "    return 'Corpus Loaded.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0b5d11b-20d2-43d7-88f9-fb02ddbec90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Corpus Loaded.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_recommender(downloaded_file , start_page=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b08185b1-f782-4d7c-b908-ce9b9722695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Give me summary of the abstract of the document\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "271b9a13-92ed-4b52-8dd2-f87b46fdd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\\Compose a comprehensive reply to the query using the search results given. \n",
    "Cite each reference using [ Page Number] notation (every result has this number at the beginning). \n",
    "Citation should be done at the end of each sentence. If the search results mention multiple subjects \n",
    "with the same name, create separate answers for each. Only include information found in the results and \n",
    "don't add any additional information. Make sure the answer is correct and don't output false content. \n",
    "If the text does not relate to the query, simply state 'Found Nothing'. Ignore outlier \n",
    "search results which has nothing to do with the question. Only answer what is asked. The \n",
    "answer should be short and concise.\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e73bd54b-5557-4585-8690-d6a18029b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_prompt(question: str) -> str:\n",
    "    topn_chunks = recommender(question)\n",
    "    results = \"\"\n",
    "    results += 'Search results:\\n\\n'\n",
    "    for c in topn_chunks:\n",
    "        results += c + '. \\n\\n' \n",
    "    message =  \"\\n\\nQuery: {}\".format(question) + \" \\n\\n\" + results + \" \\nAnswer:\"\n",
    "    texts = [f'<s>[INST] <<SYS>>\\n{DEFAULT_SYSTEM_PROMPT}\\n<</SYS>>\\n\\n']\n",
    "    texts.append(f'{message} [/INST]')\n",
    "    return ''.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5af1541e-39b8-42e1-86c4-f44fd3d89ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=get_simple_prompt(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2643776c-a1cd-4b29-b3c0-265052536a24",
   "metadata": {},
   "source": [
    "# Modeling 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4118345f-356e-4624-a6ee-2f5b25b5e518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model was loaded.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# Load the model and tokenizer\n",
    "try:\n",
    "    model_name\n",
    "    model\n",
    "    tokenizer\n",
    "except NameError:\n",
    "    print(\"Loading the model ...\")\n",
    "    model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)    \n",
    "else:\n",
    "    print(\"The model was loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "915b0ce1-6945-4f80-8ba0-d0f5b51b2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a base instruction for the model\n",
    "base_instruction  = \"Instructions: Compose a comprehensive reply to the query using the search results given. \"\\\n",
    "              \"Cite each reference using [Page Number] notation (every result has this number at the beginning). \"\\\n",
    "              \"Citation should be done at the end of each sentence. If the search results mention multiple subjects \"\\\n",
    "              \"with the same name, create separate answers for each. Only include information found in the results and \"\\\n",
    "              \"don't add any additional information. Make sure the answer is correct and don't output false content. \"\\\n",
    "              \"If the text does not relate to the query, simply state 'Found Nothing'. Ignore outlier \"\\\n",
    "              \"search results which has nothing to do with the question. Only answer what is asked. The \"\\\n",
    "              \"answer should be short and concise.\"\\\n",
    "              \"Do not include the instructions in the answer.\"\n",
    "# Define a list of sample texts that will be used as input along with the prompt\n",
    "prompt = \"What is the abstract\"\n",
    "results='[Page no. 1] \"Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works. Attention Is All You Need Ashish Vaswani∗ Google Brain avaswani@google.com Noam Shazeer∗ Google Brain noam@google.com Niki Parmar∗ Google Research nikip@google.com Jakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research llion@google.com Aidan N. Gomez∗ † University of Toronto aidan@cs.toronto.edu Łukasz Kaiser∗ Google Brain lukaszkaiser@google.com Illia Polosukhin∗ ‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly\"'\n",
    "# Combine the base instruction and the user's prompt\n",
    "combined_prompt = base_instruction + \"\\n\\nQuery: {}\".format(prompt) + \" \\n\\n\" + results + \" \\nAnswer:\"\n",
    "# Set the pad_token attribute of the tokenizer to use the end-of-sequence (eos) token as padding\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Create a batch of combined prompt\n",
    "inputs = tokenizer([combined_prompt], return_tensors=\"pt\", padding=True)\n",
    "# Get the input_ids  from the tokenizer's output\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "# Generate text using the `model.generate()` function, providing input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6490a588-6a17-4570-a09a-89e948859c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions: Compose a comprehensive reply to the query using the search results given. Cite each reference using [Page Number] notation (every result has this number at the beginning). Citation should be done at the end of each sentence. If the search results mention multiple subjects with the same name, create separate answers for each. Only include information found in the results and don't add any additional information. Make sure the answer is correct and don't output false content. If the text does not relate to the query, simply state 'Found Nothing'. Ignore outlier search results which has nothing to do with the question. Only answer what is asked. The answer should be short and concise.Do not include the instructions in the answer.\n",
      "\n",
      "Query: What is the abstract \n",
      "\n",
      "[Page no. 1] \"Provided proper attribution is provided, Google hereby grants permission to reproduce the tables and figures in this paper solely for use in journalistic or scholarly works. Attention Is All You Need Ashish Vaswani∗ Google Brain avaswani@google.com Noam Shazeer∗ Google Brain noam@google.com Niki Parmar∗ Google Research nikip@google.com Jakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research llion@google.com Aidan N. Gomez∗ † University of Toronto aidan@cs.toronto.edu Łukasz Kaiser∗ Google Brain lukaszkaiser@google.com Illia Polosukhin∗ ‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly\" \n",
      "Answer: The abstract of the paper is \"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less computation.\" [1]\n"
     ]
    }
   ],
   "source": [
    "generated_text = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=1000,\n",
    ") \n",
    "# Decode and print the generated text without special tokens\n",
    "generated_text = tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
    "# Print the generated text\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9dc5ac-a514-4eb3-bb17-20a944beb819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ArxivChat)",
   "language": "python",
   "name": "arxivchat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
